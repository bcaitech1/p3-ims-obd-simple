{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e59a2a2-0699-4559-ad44-873d7a5f0fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchcontrib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053a40dd-71c0-4db2-a188-cb46b6ed0a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install segmentation-models-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cee836-6eb7-4dd6-8530-1d9d9a8c8af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from time import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "from torchcontrib.optim import SWA\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# dataset.py 파일 필요\n",
    "from dataset import *\n",
    "from utils import label_accuracy_score, seed_everything, get_current_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21103aae-2603-4808-84a4-14d64df25253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb 사용여부 결정\n",
    "use_wandb =  # True / False\n",
    "\n",
    "if use_wandb:\n",
    "    import wandb\n",
    "    \n",
    "    # wandb run\n",
    "    run = wandb.init(project='p3-img-seg', entity='boostcamp-simple')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080f5dd2-d2ed-4f09-8ff3-82b8257ca2fa",
   "metadata": {},
   "source": [
    "## 하이퍼파라미터 세팅 및 seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36e0ca2-a9f8-409c-8500-bf743e8e5502",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"EfficientUnet\"\n",
    "encoder_name = 'timm-efficientnet-b3'\n",
    "encoder_weight = 'noisy-student'\n",
    "\n",
    "batch_size = 8\n",
    "num_epochs = 20\n",
    "learning_rate = 0.0005\n",
    "random_seed = 21\n",
    "weight_decay = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc00715-40a5-4b56-bdd7-20d762623752",
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_wandb:\n",
    "    # wandb에 사용할 하이퍼파라미터 저장\n",
    "    config = wandb.config\n",
    "    config.update({\n",
    "        \"model\": model,\n",
    "        \"encoder_name\": encoder_name,\n",
    "        \"encoder_weight\": encoder_weight,\n",
    "\n",
    "        \"batch_size\": batch_size,\n",
    "        \"num_epochs\": num_epochs,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"random_seed\": random_seed,\n",
    "        \"weight_decay\": weight_decay,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ab4afd-6250-463a-9e5d-1b243549bd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed 고정\n",
    "seed_everything(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29ba149-177a-4f8d-afb2-e5b2daa21c38",
   "metadata": {},
   "source": [
    "## 파일명 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11c24b9-cf64-403d-b986-2ec67939caf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd, hh, mm = get_current_time()\n",
    "# 모델 저장 파일 이름\n",
    "saved_dir = '/opt/ml/code/saved'\n",
    "model_file_name = f'Unet_best_model(efficient_net)_swa_{dd}{hh}{mm}.pt'\n",
    "\n",
    "# 제출 파일 이름\n",
    "submission_dir = '/opt/ml/code/submission'\n",
    "submission_file_name = f'Unet_best_model(efficient_net)_swa_{dd}{hh}{mm}.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a6fc64-0490-414c-9fe1-c6aada120473",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ab5c28-cb80-4db7-802d-bb436b057656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.json / validation.json / test.json 디렉토리 설정\n",
    "dataset_path = '/opt/ml/input/data'\n",
    "\n",
    "train_path = os.path.join(dataset_path, 'train.json')\n",
    "val_path = os.path.join(dataset_path, 'val.json')\n",
    "test_path = os.path.join(dataset_path, 'test.json')\n",
    "\n",
    "# collate_fn needs for batch\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "train_transform = A.Compose([\n",
    "                            ToTensorV2()\n",
    "                            ])\n",
    "\n",
    "val_transform = A.Compose([\n",
    "                          ToTensorV2()\n",
    "                          ])\n",
    "\n",
    "test_transform = A.Compose([\n",
    "                           ToTensorV2()\n",
    "                           ])\n",
    "\n",
    "# train dataset\n",
    "train_dataset = CustomDataLoader(data_dir=train_path, mode='train', transform=train_transform)\n",
    "\n",
    "# validation dataset\n",
    "val_dataset = CustomDataLoader(data_dir=val_path, mode='val', transform=val_transform)\n",
    "\n",
    "# test dataset\n",
    "test_dataset = CustomDataLoader(data_dir=test_path, mode='test', transform=test_transform)\n",
    "\n",
    "\n",
    "# DataLoader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True,\n",
    "                                           num_workers=4,\n",
    "                                           collate_fn=collate_fn)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset, \n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=False,\n",
    "                                         num_workers=4,\n",
    "                                         collate_fn=collate_fn)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          num_workers=4,\n",
    "                                          collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce92b9a-7f03-4196-b00e-1d3545846fac",
   "metadata": {},
   "source": [
    "## 모델 생성\n",
    "### Using SMP\n",
    "[git: segmentation-models-pytorch](https://github.com/qubvel/segmentation_models.pytorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a795c144-8c89-4c9e-ad0e-15b666abeae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = smp.Unet(\n",
    "    encoder_name=encoder_name,  # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "    encoder_weights=encoder_weight,      # use 'noisy-student' pre-trained weights for encoder initialization\n",
    "    in_channels=3,                        # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "    classes=12,                           # model output channels (number of classes in your dataset)\n",
    ")\n",
    "\n",
    "model.to(device)\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acd0994-58b1-41c1-a032-770623ce865d",
   "metadata": {},
   "source": [
    "## Loss function, Optimizer 정의\n",
    "### Using SWA\n",
    "[pytorch: Stochastic Weight Averaging in PyTorch](https://pytorch.org/blog/stochastic-weight-averaging-in-pytorch/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdbb4ba-4123-4eba-b4aa-bba1b58654cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "swa_start = 10\n",
    "swa_freq = 5\n",
    "swa_lr = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a06f869-83d2-4edf-bb0a-77341befc983",
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_wandb:\n",
    "    # wandb에 사용할 loss, optimizer, 하이퍼 파라미터 저장\n",
    "    config.update({\n",
    "        \"criterion\": \"nn.CrossEntropyLoss()\",\n",
    "        \"base_optimizer\": \"Adam\",\n",
    "        \"optimizer\": \"SWA\",\n",
    "        \n",
    "        \"swa_start\": swa_start,\n",
    "        \"swa_freq\": swa_freq,\n",
    "        \"swa_lr\": swa_lr,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af77153-5f7b-4a77-84fe-b47e47ac01d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = smp.utils.losses.DiceLoss()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "metrics = [\n",
    "    smp.utils.metrics.IoU(threshold=0.5),\n",
    "]\n",
    "\n",
    "base_optimizer = torch.optim.Adam([ \n",
    "    dict(params=model.parameters(), lr=learning_rate),\n",
    "])\n",
    "optimizer = SWA(base_optimizer, swa_start=swa_start, swa_freq=swa_freq, swa_lr=swa_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0baaae-d48d-47da-92d2-7b1d9f54f1cb",
   "metadata": {},
   "source": [
    "## 모델 저장 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b36e76-2378-40d2-9f80-38c22c502f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장 함수 정의\n",
    "val_every = 1 \n",
    "\n",
    "if not os.path.isdir(saved_dir):\n",
    "    os.mkdir(saved_dir)\n",
    "    \n",
    "def save_model(model, saved_dir, file_name=model_file_name):\n",
    "    check_point = {'net': model.state_dict()}\n",
    "    output_path = os.path.join(saved_dir, file_name)\n",
    "    torch.save(model.state_dict(), output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060884a0-a030-4be5-8df5-ecd73ab23932",
   "metadata": {},
   "source": [
    "## train, validation 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac86f51-350d-4303-bc8e-9d2383e293a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(num_epochs, model, data_loader, val_loader, criterion, optimizer, saved_dir, val_every, device):\n",
    "    print('Start training..')\n",
    "    best_loss = 9999999\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for step, (images, masks, _) in enumerate(data_loader):\n",
    "            images = torch.stack(images)       # (batch, channel, height, width)\n",
    "            masks = torch.stack(masks).long()  # (batch, channel, height, width)\n",
    "            \n",
    "            # gpu 연산을 위해 device 할당\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "                  \n",
    "            # inference\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # loss 계산 (cross entropy loss)\n",
    "            loss = criterion(outputs, masks)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if step > 10 and step % 5 == 0:\n",
    "                optimizer.update_swa()\n",
    "            \n",
    "            # step 주기에 따른 loss 출력\n",
    "            if (step + 1) % 25 == 0:\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(\n",
    "                    epoch+1, num_epochs, step+1, len(train_loader), loss.item()))\n",
    "                if use_wandb:\n",
    "                    wandb.log({\"train_loss\": loss})\n",
    "                \n",
    "        # validation 주기에 따른 loss 출력 및 best model 저장\n",
    "        if (epoch + 1) % val_every == 0:\n",
    "            avrg_loss = validation(epoch + 1, model, val_loader, criterion, device)\n",
    "            if avrg_loss < best_loss:\n",
    "                print('Best performance at epoch: {}'.format(epoch + 1))\n",
    "                print('Save model in', saved_dir)\n",
    "                best_loss = avrg_loss\n",
    "                save_model(model, saved_dir)\n",
    "                \n",
    "    optimizer.swap_swa_sgd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c51c336-a440-441f-9bbc-a68ba35e57ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(epoch, model, data_loader, criterion, device):\n",
    "    print('Start validation #{}'.format(epoch))\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_loss = 0\n",
    "        cnt = 0\n",
    "        mIoU_list = []\n",
    "        for step, (images, masks, _) in enumerate(data_loader):\n",
    "            \n",
    "            images = torch.stack(images)       # (batch, channel, height, width)\n",
    "            masks = torch.stack(masks).long()  # (batch, channel, height, width)\n",
    "\n",
    "            images, masks = images.to(device), masks.to(device)   \n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "            total_loss += loss\n",
    "            cnt += 1\n",
    "            \n",
    "            outputs = torch.argmax(outputs.squeeze(), dim=1).detach().cpu().numpy()\n",
    "\n",
    "            mIoU = label_accuracy_score(masks.detach().cpu().numpy(), outputs, n_class=12)[2]\n",
    "            mIoU_list.append(mIoU)\n",
    "            \n",
    "        avrg_loss = total_loss / cnt\n",
    "        mIoU = np.mean(mIoU_list)\n",
    "        print('Validation #{}  Average Loss: {:.4f}, mIoU: {:.4f}'.format(epoch, avrg_loss, mIoU))\n",
    "        if use_wandb:\n",
    "            wandb.log({\"val_loss\": avrg_loss, \"val_mIoU\": mIoU})\n",
    "\n",
    "    return avrg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba034b6-d3b4-489c-b98b-73fb1c5dbeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습시작 시간 출력\n",
    "s_dd, s_hh, s_mm = get_current_time()\n",
    "\n",
    "# 학습 시작\n",
    "train(num_epochs, model, train_loader, val_loader, criterion, optimizer, saved_dir, val_every, device)\n",
    "\n",
    "# 학습종료 시간 출력\n",
    "e_dd, e_hh, e_mm = get_current_time()\n",
    "print(f'start: {s_dd}일 {s_hh}시 {s_mm}분')\n",
    "print(f'end: {e_dd}일 {e_hh}시 {e_mm}분')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138daf63-f111-497f-9bdd-3c670e8865fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_wandb:\n",
    "    # wandb 종료\n",
    "    run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f420328-ed19-42b8-9d00-264fad8131eb",
   "metadata": {},
   "source": [
    "## 저장된 model 불러오기 (학습된 이후)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50bb834-2f7d-4b2b-a28d-3fa607e6b8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best model 저장된 경로\n",
    "model_path = os.path.join(saved_dir, model_file_name)\n",
    "\n",
    "# best model 불러오기\n",
    "checkpoint = torch.load(model_path, map_location=device)\n",
    "model.load_state_dict(checkpoint)\n",
    "\n",
    "# 추론을 실행하기 전에는 반드시 설정 (batch normalization, dropout 를 평가 모드로 설정)\n",
    "# model.eval() # test 함수에서 model.eval() 실행\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37acda6-6f30-4154-b789-782c3552a07f",
   "metadata": {},
   "source": [
    "## submission을 위한 test 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1912b7-1ddf-44b4-8456-1a4700beab35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, data_loader, device):\n",
    "    size = 256\n",
    "    transform = A.Compose([A.Resize(256, 256)])\n",
    "    print('Start prediction.')\n",
    "    model.eval()\n",
    "    \n",
    "    file_name_list = []\n",
    "    preds_array = np.empty((0, size*size), dtype=np.long)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for step, (imgs, image_infos) in enumerate(test_loader):\n",
    "\n",
    "            # inference (512 x 512)\n",
    "            outs = model(torch.stack(imgs).to(device))\n",
    "            oms = torch.argmax(outs.squeeze(), dim=1).detach().cpu().numpy()\n",
    "            \n",
    "            # resize (256 x 256)\n",
    "            temp_mask = []\n",
    "            for img, mask in zip(np.stack(imgs), oms):\n",
    "                transformed = transform(image=img, mask=mask)\n",
    "                mask = transformed['mask']\n",
    "                temp_mask.append(mask)\n",
    "\n",
    "            oms = np.array(temp_mask)\n",
    "            \n",
    "            oms = oms.reshape([oms.shape[0], size*size]).astype(int)\n",
    "            preds_array = np.vstack((preds_array, oms))\n",
    "            \n",
    "            file_name_list.append([i['file_name'] for i in image_infos])\n",
    "    print(\"End prediction.\")\n",
    "    file_names = [y for x in file_name_list for y in x]\n",
    "    \n",
    "    return file_names, preds_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7cbb38-3e70-455a-bf0b-ab20b3129158",
   "metadata": {},
   "source": [
    "## submission.csv 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8ef792-06d6-4a7b-a527-40a76df45253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_submisson.csv 열기\n",
    "submission = pd.read_csv(os.path.join(submission_dir, 'sample_submission.csv'), index_col=None)\n",
    "\n",
    "# test set에 대한 prediction\n",
    "file_names, preds = test(model, test_loader, device)\n",
    "\n",
    "# PredictionString 대입\n",
    "for file_name, string in zip(file_names, preds):\n",
    "    submission = submission.append({\"image_id\" : file_name, \"PredictionString\" : ' '.join(str(e) for e in string.tolist())}, \n",
    "                                   ignore_index=True)\n",
    "\n",
    "# submission.csv로 저장\n",
    "submission.to_csv(os.path.join(submission_dir, submission_file_name), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1645ae5-a65b-4fd3-af7f-2f84c1727d43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
