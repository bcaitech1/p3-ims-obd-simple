{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e59a2a2-0699-4559-ad44-873d7a5f0fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchcontrib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053a40dd-71c0-4db2-a188-cb46b6ed0a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install segmentation-models-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89cee836-6eb7-4dd6-8530-1d9d9a8c8af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from time import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "from torchcontrib.optim import SWA\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# dataset.py 파일 필요\n",
    "from dataset import *\n",
    "from utils import label_accuracy_score, seed_everything, get_current_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21103aae-2603-4808-84a4-14d64df25253",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjaegyeong\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.28 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.27<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">peach-night-15</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/boostcamp-simple/p3-img-seg\" target=\"_blank\">https://wandb.ai/boostcamp-simple/p3-img-seg</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/boostcamp-simple/p3-img-seg/runs/8tnlps8f\" target=\"_blank\">https://wandb.ai/boostcamp-simple/p3-img-seg/runs/8tnlps8f</a><br/>\n",
       "                Run data is saved locally in <code>/opt/ml/code/notebook/wandb/run-20210430_104739-8tnlps8f</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# wandb 사용여부 결정\n",
    "use_wandb =  # True / False\n",
    "\n",
    "if use_wandb:\n",
    "    import wandb\n",
    "    \n",
    "    # wandb run\n",
    "    run = wandb.init(project='p3-img-seg', entity='boostcamp-simple')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080f5dd2-d2ed-4f09-8ff3-82b8257ca2fa",
   "metadata": {},
   "source": [
    "## 하이퍼파라미터 세팅 및 seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a36e0ca2-a9f8-409c-8500-bf743e8e5502",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"EfficientUnet\"\n",
    "encoder_name = 'timm-efficientnet-b3'\n",
    "encoder_weight = 'noisy-student'\n",
    "\n",
    "batch_size = 8\n",
    "num_epochs = 20\n",
    "learning_rate = 0.0005\n",
    "random_seed = 21\n",
    "weight_decay = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bc00715-40a5-4b56-bdd7-20d762623752",
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_wandb:\n",
    "    # wandb에 사용할 하이퍼파라미터 저장\n",
    "    config = wandb.config\n",
    "    config.update({\n",
    "        \"model\": model,\n",
    "        \"encoder_name\": encoder_name,\n",
    "        \"encoder_weight\": encoder_weight,\n",
    "\n",
    "        \"batch_size\": batch_size,\n",
    "        \"num_epochs\": num_epochs,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"random_seed\": random_seed,\n",
    "        \"weight_decay\": weight_decay,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93ab4afd-6250-463a-9e5d-1b243549bd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed 고정\n",
    "seed_everything(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29ba149-177a-4f8d-afb2-e5b2daa21c38",
   "metadata": {},
   "source": [
    "## 파일명 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d11c24b9-cf64-403d-b986-2ec67939caf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd, hh, mm = get_current_time()\n",
    "# 모델 저장 파일 이름\n",
    "saved_dir = '/opt/ml/code/saved'\n",
    "model_file_name = f'Unet_best_model(efficient_net)_swa_{dd}{hh}{mm}.pt'\n",
    "\n",
    "# 제출 파일 이름\n",
    "submission_dir = '/opt/ml/code/submission'\n",
    "submission_file_name = f'Baseline_FCN8s(pretrained)_swa_{dd}{hh}{mm}.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a6fc64-0490-414c-9fe1-c6aada120473",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38ab5c28-cb80-4db7-802d-bb436b057656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=3.74s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=1.52s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# train.json / validation.json / test.json 디렉토리 설정\n",
    "dataset_path = '/opt/ml/input/data'\n",
    "\n",
    "train_path = os.path.join(dataset_path, 'train.json')\n",
    "val_path = os.path.join(dataset_path, 'val.json')\n",
    "test_path = os.path.join(dataset_path, 'test.json')\n",
    "\n",
    "# collate_fn needs for batch\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "train_transform = A.Compose([\n",
    "                            ToTensorV2()\n",
    "                            ])\n",
    "\n",
    "val_transform = A.Compose([\n",
    "                          ToTensorV2()\n",
    "                          ])\n",
    "\n",
    "test_transform = A.Compose([\n",
    "                           ToTensorV2()\n",
    "                           ])\n",
    "\n",
    "# train dataset\n",
    "train_dataset = CustomDataLoader(data_dir=train_path, mode='train', transform=train_transform)\n",
    "\n",
    "# validation dataset\n",
    "val_dataset = CustomDataLoader(data_dir=val_path, mode='val', transform=val_transform)\n",
    "\n",
    "# test dataset\n",
    "test_dataset = CustomDataLoader(data_dir=test_path, mode='test', transform=test_transform)\n",
    "\n",
    "\n",
    "# DataLoader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True,\n",
    "                                           num_workers=4,\n",
    "                                           collate_fn=collate_fn)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset, \n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=False,\n",
    "                                         num_workers=4,\n",
    "                                         collate_fn=collate_fn)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          num_workers=4,\n",
    "                                          collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce92b9a-7f03-4196-b00e-1d3545846fac",
   "metadata": {},
   "source": [
    "## 모델 생성\n",
    "### Using SMP\n",
    "[git: segmentation-models-pytorch](https://github.com/qubvel/segmentation_models.pytorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a795c144-8c89-4c9e-ad0e-15b666abeae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = smp.Unet(\n",
    "    encoder_name=encoder_name,  # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "    encoder_weights=encoder_weight,      # use 'noisy-student' pre-trained weights for encoder initialization\n",
    "    in_channels=3,                        # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "    classes=12,                           # model output channels (number of classes in your dataset)\n",
    ")\n",
    "\n",
    "model.to(device)\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acd0994-58b1-41c1-a032-770623ce865d",
   "metadata": {},
   "source": [
    "## Loss function, Optimizer 정의\n",
    "### Using SWA\n",
    "[pytorch: Stochastic Weight Averaging in PyTorch](https://pytorch.org/blog/stochastic-weight-averaging-in-pytorch/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6cdbb4ba-4123-4eba-b4aa-bba1b58654cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "swa_start = 10\n",
    "swa_freq = 5\n",
    "swa_lr = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a06f869-83d2-4edf-bb0a-77341befc983",
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_wandb:\n",
    "    # wandb에 사용할 loss, optimizer, 하이퍼 파라미터 저장\n",
    "    config.update({\n",
    "        \"criterion\": \"nn.CrossEntropyLoss()\"\n",
    "        \"base_optimizer\": \"Adam\"\n",
    "        \"optimizer\": \"SWA\"\n",
    "        \n",
    "        \"swa_start\": swa_start,\n",
    "        \"swa_freq\": swa_freq,\n",
    "        \"swa_lr\": swa_lr,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0af77153-5f7b-4a77-84fe-b47e47ac01d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = smp.utils.losses.DiceLoss()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "metrics = [\n",
    "    smp.utils.metrics.IoU(threshold=0.5),\n",
    "]\n",
    "\n",
    "base_optimizer = torch.optim.Adam([ \n",
    "    dict(params=model.parameters(), lr=learning_rate),\n",
    "])\n",
    "optimizer = SWA(base_optimizer, swa_start=swa_start, swa_freq=swa_freq, swa_lr=swa_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0baaae-d48d-47da-92d2-7b1d9f54f1cb",
   "metadata": {},
   "source": [
    "## 모델 저장 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55b36e76-2378-40d2-9f80-38c22c502f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장 함수 정의\n",
    "val_every = 1 \n",
    "\n",
    "if not os.path.isdir(saved_dir):                                                           \n",
    "    os.mkdir(saved_dir)\n",
    "    \n",
    "def save_model(model, saved_dir, file_name=model_file_name):\n",
    "    check_point = {'net': model.state_dict()}\n",
    "    output_path = os.path.join(saved_dir, file_name)\n",
    "    torch.save(model.state_dict(), output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060884a0-a030-4be5-8df5-ecd73ab23932",
   "metadata": {},
   "source": [
    "## train, validation 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ac86f51-350d-4303-bc8e-9d2383e293a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(num_epochs, model, data_loader, val_loader, criterion, optimizer, saved_dir, val_every, device):\n",
    "    print('Start training..')\n",
    "    best_loss = 9999999\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for step, (images, masks, _) in enumerate(data_loader):\n",
    "            images = torch.stack(images)       # (batch, channel, height, width)\n",
    "            masks = torch.stack(masks).long()  # (batch, channel, height, width)\n",
    "            \n",
    "            # gpu 연산을 위해 device 할당\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "                  \n",
    "            # inference\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # loss 계산 (cross entropy loss)\n",
    "            loss = criterion(outputs, masks)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if step > 10 and step % 5 == 0:\n",
    "                optimizer.update_swa()\n",
    "            \n",
    "            # step 주기에 따른 loss 출력\n",
    "            if (step + 1) % 25 == 0:\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(\n",
    "                    epoch+1, num_epochs, step+1, len(train_loader), loss.item()))\n",
    "                if use_wandb:\n",
    "                    wandb.log({\"train_loss\": loss})\n",
    "                \n",
    "        # validation 주기에 따른 loss 출력 및 best model 저장\n",
    "        if (epoch + 1) % val_every == 0:\n",
    "            avrg_loss = validation(epoch + 1, model, val_loader, criterion, device)\n",
    "            if avrg_loss < best_loss:\n",
    "                print('Best performance at epoch: {}'.format(epoch + 1))\n",
    "                print('Save model in', saved_dir)\n",
    "                best_loss = avrg_loss\n",
    "                save_model(model, saved_dir)\n",
    "                \n",
    "    optimizer.swap_swa_sgd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c51c336-a440-441f-9bbc-a68ba35e57ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(epoch, model, data_loader, criterion, device):\n",
    "    print('Start validation #{}'.format(epoch))\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_loss = 0\n",
    "        cnt = 0\n",
    "        mIoU_list = []\n",
    "        for step, (images, masks, _) in enumerate(data_loader):\n",
    "            \n",
    "            images = torch.stack(images)       # (batch, channel, height, width)\n",
    "            masks = torch.stack(masks).long()  # (batch, channel, height, width)\n",
    "\n",
    "            images, masks = images.to(device), masks.to(device)   \n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "            total_loss += loss\n",
    "            cnt += 1\n",
    "            \n",
    "            outputs = torch.argmax(outputs.squeeze(), dim=1).detach().cpu().numpy()\n",
    "\n",
    "            mIoU = label_accuracy_score(masks.detach().cpu().numpy(), outputs, n_class=12)[2]\n",
    "            mIoU_list.append(mIoU)\n",
    "            \n",
    "        avrg_loss = total_loss / cnt\n",
    "        mIoU = np.mean(mIoU_list)\n",
    "        print('Validation #{}  Average Loss: {:.4f}, mIoU: {:.4f}'.format(epoch, avrg_loss, mIoU))\n",
    "        if use_wandb:\n",
    "            wandb.log({\"val_loss\": avrg_loss, \"val_mIoU\": mIoU})\n",
    "\n",
    "    return avrg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ba034b6-d3b4-489c-b98b-73fb1c5dbeef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start: 30일 19시 48분\n",
      "Start training..\n",
      "Epoch [1/20], Step [25/328], Loss: 0.8298\n",
      "Epoch [1/20], Step [50/328], Loss: 0.7281\n",
      "Epoch [1/20], Step [75/328], Loss: 0.6412\n",
      "Epoch [1/20], Step [100/328], Loss: 0.5672\n",
      "Epoch [1/20], Step [125/328], Loss: 0.6438\n",
      "Epoch [1/20], Step [150/328], Loss: 0.8134\n",
      "Epoch [1/20], Step [175/328], Loss: 0.6566\n",
      "Epoch [1/20], Step [200/328], Loss: 1.0190\n",
      "Epoch [1/20], Step [225/328], Loss: 0.6752\n",
      "Epoch [1/20], Step [250/328], Loss: 0.8437\n",
      "Epoch [1/20], Step [275/328], Loss: 0.5398\n",
      "Epoch [1/20], Step [300/328], Loss: 0.5871\n",
      "Epoch [1/20], Step [325/328], Loss: 0.9595\n",
      "Start validation #1\n",
      "Validation #1  Average Loss: 0.5960, mIoU: 0.2355\n",
      "Best performance at epoch: 1\n",
      "Save model in /opt/ml/code/saved\n",
      "Epoch [2/20], Step [25/328], Loss: 0.4969\n",
      "Epoch [2/20], Step [50/328], Loss: 0.7750\n",
      "Epoch [2/20], Step [75/328], Loss: 0.6191\n",
      "Epoch [2/20], Step [100/328], Loss: 1.0470\n",
      "Epoch [2/20], Step [125/328], Loss: 0.7540\n",
      "Epoch [2/20], Step [150/328], Loss: 0.6821\n",
      "Epoch [2/20], Step [175/328], Loss: 0.7417\n",
      "Epoch [2/20], Step [200/328], Loss: 0.4168\n",
      "Epoch [2/20], Step [225/328], Loss: 0.8031\n",
      "Epoch [2/20], Step [250/328], Loss: 0.6785\n",
      "Epoch [2/20], Step [275/328], Loss: 0.7197\n",
      "Epoch [2/20], Step [300/328], Loss: 0.3764\n",
      "Epoch [2/20], Step [325/328], Loss: 0.4572\n",
      "Start validation #2\n",
      "Validation #2  Average Loss: 0.5687, mIoU: 0.2469\n",
      "Best performance at epoch: 2\n",
      "Save model in /opt/ml/code/saved\n",
      "Epoch [3/20], Step [25/328], Loss: 0.5449\n",
      "Epoch [3/20], Step [50/328], Loss: 0.5094\n",
      "Epoch [3/20], Step [75/328], Loss: 0.4884\n",
      "Epoch [3/20], Step [100/328], Loss: 0.6311\n",
      "Epoch [3/20], Step [125/328], Loss: 0.5721\n",
      "Epoch [3/20], Step [150/328], Loss: 0.4055\n",
      "Epoch [3/20], Step [175/328], Loss: 0.5547\n",
      "Epoch [3/20], Step [200/328], Loss: 0.6646\n",
      "Epoch [3/20], Step [225/328], Loss: 0.7482\n",
      "Epoch [3/20], Step [250/328], Loss: 0.4630\n",
      "Epoch [3/20], Step [275/328], Loss: 0.5098\n",
      "Epoch [3/20], Step [300/328], Loss: 0.4617\n",
      "Epoch [3/20], Step [325/328], Loss: 0.7010\n",
      "Start validation #3\n",
      "Validation #3  Average Loss: 0.5994, mIoU: 0.2405\n",
      "Epoch [4/20], Step [25/328], Loss: 0.6879\n",
      "Epoch [4/20], Step [50/328], Loss: 0.4234\n",
      "Epoch [4/20], Step [75/328], Loss: 0.8997\n",
      "Epoch [4/20], Step [100/328], Loss: 0.3451\n",
      "Epoch [4/20], Step [125/328], Loss: 0.6373\n",
      "Epoch [4/20], Step [150/328], Loss: 0.3275\n",
      "Epoch [4/20], Step [175/328], Loss: 0.4140\n",
      "Epoch [4/20], Step [200/328], Loss: 0.4525\n",
      "Epoch [4/20], Step [225/328], Loss: 0.5523\n",
      "Epoch [4/20], Step [250/328], Loss: 0.5689\n",
      "Epoch [4/20], Step [275/328], Loss: 0.4994\n",
      "Epoch [4/20], Step [300/328], Loss: 0.3272\n",
      "Epoch [4/20], Step [325/328], Loss: 0.5807\n",
      "Start validation #4\n",
      "Validation #4  Average Loss: 0.5497, mIoU: 0.2483\n",
      "Best performance at epoch: 4\n",
      "Save model in /opt/ml/code/saved\n",
      "Epoch [5/20], Step [25/328], Loss: 0.5785\n",
      "Epoch [5/20], Step [50/328], Loss: 0.5947\n",
      "Epoch [5/20], Step [75/328], Loss: 0.3054\n",
      "Epoch [5/20], Step [100/328], Loss: 0.4071\n",
      "Epoch [5/20], Step [125/328], Loss: 0.3562\n",
      "Epoch [5/20], Step [150/328], Loss: 0.5993\n",
      "Epoch [5/20], Step [175/328], Loss: 1.0729\n",
      "Epoch [5/20], Step [200/328], Loss: 0.3328\n",
      "Epoch [5/20], Step [225/328], Loss: 0.6168\n",
      "Epoch [5/20], Step [250/328], Loss: 0.3940\n",
      "Epoch [5/20], Step [275/328], Loss: 0.3752\n",
      "Epoch [5/20], Step [300/328], Loss: 0.5294\n",
      "Epoch [5/20], Step [325/328], Loss: 0.6144\n",
      "Start validation #5\n",
      "Validation #5  Average Loss: 0.6245, mIoU: 0.2531\n",
      "Epoch [6/20], Step [25/328], Loss: 0.4158\n",
      "Epoch [6/20], Step [50/328], Loss: 0.5259\n",
      "Epoch [6/20], Step [75/328], Loss: 0.2614\n",
      "Epoch [6/20], Step [100/328], Loss: 0.3438\n",
      "Epoch [6/20], Step [125/328], Loss: 0.3947\n",
      "Epoch [6/20], Step [150/328], Loss: 0.4881\n",
      "Epoch [6/20], Step [175/328], Loss: 0.6223\n",
      "Epoch [6/20], Step [200/328], Loss: 0.8115\n",
      "Epoch [6/20], Step [225/328], Loss: 0.4176\n",
      "Epoch [6/20], Step [250/328], Loss: 0.4828\n",
      "Epoch [6/20], Step [275/328], Loss: 0.4193\n",
      "Epoch [6/20], Step [300/328], Loss: 0.4891\n",
      "Epoch [6/20], Step [325/328], Loss: 0.4933\n",
      "Start validation #6\n",
      "Validation #6  Average Loss: 0.5140, mIoU: 0.2792\n",
      "Best performance at epoch: 6\n",
      "Save model in /opt/ml/code/saved\n",
      "Epoch [7/20], Step [25/328], Loss: 0.8292\n",
      "Epoch [7/20], Step [50/328], Loss: 1.0253\n",
      "Epoch [7/20], Step [75/328], Loss: 0.4113\n",
      "Epoch [7/20], Step [100/328], Loss: 0.5696\n",
      "Epoch [7/20], Step [125/328], Loss: 0.3591\n",
      "Epoch [7/20], Step [150/328], Loss: 0.4046\n",
      "Epoch [7/20], Step [175/328], Loss: 0.4755\n",
      "Epoch [7/20], Step [200/328], Loss: 0.4041\n",
      "Epoch [7/20], Step [225/328], Loss: 0.3888\n",
      "Epoch [7/20], Step [250/328], Loss: 0.4858\n",
      "Epoch [7/20], Step [275/328], Loss: 0.4582\n",
      "Epoch [7/20], Step [300/328], Loss: 0.5328\n",
      "Epoch [7/20], Step [325/328], Loss: 0.4323\n",
      "Start validation #7\n",
      "Validation #7  Average Loss: 0.4842, mIoU: 0.2655\n",
      "Best performance at epoch: 7\n",
      "Save model in /opt/ml/code/saved\n",
      "Epoch [8/20], Step [25/328], Loss: 0.2949\n",
      "Epoch [8/20], Step [50/328], Loss: 0.4452\n",
      "Epoch [8/20], Step [75/328], Loss: 1.0652\n",
      "Epoch [8/20], Step [100/328], Loss: 0.4837\n",
      "Epoch [8/20], Step [125/328], Loss: 0.4140\n",
      "Epoch [8/20], Step [150/328], Loss: 0.5871\n",
      "Epoch [8/20], Step [175/328], Loss: 0.5856\n",
      "Epoch [8/20], Step [200/328], Loss: 0.3074\n",
      "Epoch [8/20], Step [225/328], Loss: 0.3965\n",
      "Epoch [8/20], Step [250/328], Loss: 0.6946\n",
      "Epoch [8/20], Step [275/328], Loss: 0.6742\n",
      "Epoch [8/20], Step [300/328], Loss: 0.4276\n",
      "Epoch [8/20], Step [325/328], Loss: 0.3391\n",
      "Start validation #8\n",
      "Validation #8  Average Loss: 0.4882, mIoU: 0.2854\n",
      "Epoch [9/20], Step [25/328], Loss: 0.3217\n",
      "Epoch [9/20], Step [50/328], Loss: 0.5713\n",
      "Epoch [9/20], Step [75/328], Loss: 0.5205\n",
      "Epoch [9/20], Step [100/328], Loss: 0.7811\n",
      "Epoch [9/20], Step [125/328], Loss: 0.4511\n",
      "Epoch [9/20], Step [150/328], Loss: 0.5245\n",
      "Epoch [9/20], Step [175/328], Loss: 0.3881\n",
      "Epoch [9/20], Step [200/328], Loss: 0.4851\n",
      "Epoch [9/20], Step [225/328], Loss: 0.7642\n",
      "Epoch [9/20], Step [250/328], Loss: 0.3212\n",
      "Epoch [9/20], Step [275/328], Loss: 0.4258\n",
      "Epoch [9/20], Step [300/328], Loss: 1.3544\n",
      "Epoch [9/20], Step [325/328], Loss: 0.8190\n",
      "Start validation #9\n",
      "Validation #9  Average Loss: 0.4534, mIoU: 0.2798\n",
      "Best performance at epoch: 9\n",
      "Save model in /opt/ml/code/saved\n",
      "Epoch [10/20], Step [25/328], Loss: 0.3585\n",
      "Epoch [10/20], Step [50/328], Loss: 0.3919\n",
      "Epoch [10/20], Step [75/328], Loss: 0.2678\n",
      "Epoch [10/20], Step [100/328], Loss: 0.5871\n",
      "Epoch [10/20], Step [125/328], Loss: 0.6911\n",
      "Epoch [10/20], Step [150/328], Loss: 0.3694\n",
      "Epoch [10/20], Step [175/328], Loss: 0.3535\n",
      "Epoch [10/20], Step [200/328], Loss: 0.4835\n",
      "Epoch [10/20], Step [225/328], Loss: 0.6463\n",
      "Epoch [10/20], Step [250/328], Loss: 0.6456\n",
      "Epoch [10/20], Step [275/328], Loss: 0.4507\n",
      "Epoch [10/20], Step [300/328], Loss: 0.3600\n",
      "Epoch [10/20], Step [325/328], Loss: 0.4707\n",
      "Start validation #10\n",
      "Validation #10  Average Loss: 0.4693, mIoU: 0.2888\n",
      "Epoch [11/20], Step [25/328], Loss: 0.7213\n",
      "Epoch [11/20], Step [50/328], Loss: 0.3638\n",
      "Epoch [11/20], Step [75/328], Loss: 0.4440\n",
      "Epoch [11/20], Step [100/328], Loss: 0.3481\n",
      "Epoch [11/20], Step [125/328], Loss: 0.7657\n",
      "Epoch [11/20], Step [150/328], Loss: 0.5920\n",
      "Epoch [11/20], Step [175/328], Loss: 0.3000\n",
      "Epoch [11/20], Step [200/328], Loss: 0.4228\n",
      "Epoch [11/20], Step [225/328], Loss: 0.6158\n",
      "Epoch [11/20], Step [250/328], Loss: 0.4634\n",
      "Epoch [11/20], Step [275/328], Loss: 0.3705\n",
      "Epoch [11/20], Step [300/328], Loss: 0.5326\n",
      "Epoch [11/20], Step [325/328], Loss: 0.5374\n",
      "Start validation #11\n",
      "Validation #11  Average Loss: 0.4785, mIoU: 0.2775\n",
      "Epoch [12/20], Step [25/328], Loss: 0.4782\n",
      "Epoch [12/20], Step [50/328], Loss: 0.3883\n",
      "Epoch [12/20], Step [75/328], Loss: 0.5724\n",
      "Epoch [12/20], Step [100/328], Loss: 0.8798\n",
      "Epoch [12/20], Step [125/328], Loss: 0.3684\n",
      "Epoch [12/20], Step [150/328], Loss: 0.8348\n",
      "Epoch [12/20], Step [175/328], Loss: 0.5979\n",
      "Epoch [12/20], Step [200/328], Loss: 0.3423\n",
      "Epoch [12/20], Step [225/328], Loss: 0.4749\n",
      "Epoch [12/20], Step [250/328], Loss: 0.4726\n",
      "Epoch [12/20], Step [275/328], Loss: 0.7300\n",
      "Epoch [12/20], Step [300/328], Loss: 0.3651\n",
      "Epoch [12/20], Step [325/328], Loss: 0.4296\n",
      "Start validation #12\n",
      "Validation #12  Average Loss: 0.4625, mIoU: 0.2859\n",
      "Epoch [13/20], Step [25/328], Loss: 0.4065\n",
      "Epoch [13/20], Step [50/328], Loss: 0.7214\n",
      "Epoch [13/20], Step [75/328], Loss: 0.2354\n",
      "Epoch [13/20], Step [100/328], Loss: 0.6198\n",
      "Epoch [13/20], Step [125/328], Loss: 0.2707\n",
      "Epoch [13/20], Step [150/328], Loss: 0.6774\n",
      "Epoch [13/20], Step [175/328], Loss: 0.4585\n",
      "Epoch [13/20], Step [200/328], Loss: 0.5551\n",
      "Epoch [13/20], Step [225/328], Loss: 0.2467\n",
      "Epoch [13/20], Step [250/328], Loss: 0.5538\n",
      "Epoch [13/20], Step [275/328], Loss: 0.3240\n",
      "Epoch [13/20], Step [300/328], Loss: 0.3112\n",
      "Epoch [13/20], Step [325/328], Loss: 0.2893\n",
      "Start validation #13\n",
      "Validation #13  Average Loss: 0.4953, mIoU: 0.2988\n",
      "Epoch [14/20], Step [25/328], Loss: 0.2971\n",
      "Epoch [14/20], Step [50/328], Loss: 0.4336\n",
      "Epoch [14/20], Step [75/328], Loss: 0.4330\n",
      "Epoch [14/20], Step [100/328], Loss: 0.3931\n",
      "Epoch [14/20], Step [125/328], Loss: 0.4056\n",
      "Epoch [14/20], Step [150/328], Loss: 0.4410\n",
      "Epoch [14/20], Step [175/328], Loss: 0.3267\n",
      "Epoch [14/20], Step [200/328], Loss: 0.2177\n",
      "Epoch [14/20], Step [225/328], Loss: 0.3212\n",
      "Epoch [14/20], Step [250/328], Loss: 0.4398\n",
      "Epoch [14/20], Step [275/328], Loss: 0.3811\n",
      "Epoch [14/20], Step [300/328], Loss: 0.2866\n",
      "Epoch [14/20], Step [325/328], Loss: 0.4443\n",
      "Start validation #14\n",
      "Validation #14  Average Loss: 0.4384, mIoU: 0.2598\n",
      "Best performance at epoch: 14\n",
      "Save model in /opt/ml/code/saved\n",
      "Epoch [15/20], Step [25/328], Loss: 0.2085\n",
      "Epoch [15/20], Step [50/328], Loss: 0.5513\n",
      "Epoch [15/20], Step [75/328], Loss: 0.2271\n",
      "Epoch [15/20], Step [100/328], Loss: 0.2136\n",
      "Epoch [15/20], Step [125/328], Loss: 0.2695\n",
      "Epoch [15/20], Step [150/328], Loss: 0.4185\n",
      "Epoch [15/20], Step [175/328], Loss: 0.3063\n",
      "Epoch [15/20], Step [200/328], Loss: 0.4832\n",
      "Epoch [15/20], Step [225/328], Loss: 0.5411\n",
      "Epoch [15/20], Step [250/328], Loss: 0.2775\n",
      "Epoch [15/20], Step [275/328], Loss: 0.6509\n",
      "Epoch [15/20], Step [300/328], Loss: 0.6905\n",
      "Epoch [15/20], Step [325/328], Loss: 0.2463\n",
      "Start validation #15\n",
      "Validation #15  Average Loss: 0.4609, mIoU: 0.2927\n",
      "Epoch [16/20], Step [25/328], Loss: 0.2846\n",
      "Epoch [16/20], Step [50/328], Loss: 0.3068\n",
      "Epoch [16/20], Step [75/328], Loss: 0.4111\n",
      "Epoch [16/20], Step [100/328], Loss: 0.2907\n",
      "Epoch [16/20], Step [125/328], Loss: 0.4196\n",
      "Epoch [16/20], Step [150/328], Loss: 0.3732\n",
      "Epoch [16/20], Step [175/328], Loss: 0.3101\n",
      "Epoch [16/20], Step [200/328], Loss: 0.6627\n",
      "Epoch [16/20], Step [225/328], Loss: 0.5964\n",
      "Epoch [16/20], Step [250/328], Loss: 0.4063\n",
      "Epoch [16/20], Step [275/328], Loss: 0.2203\n",
      "Epoch [16/20], Step [300/328], Loss: 0.4293\n",
      "Epoch [16/20], Step [325/328], Loss: 0.3160\n",
      "Start validation #16\n",
      "Validation #16  Average Loss: 0.4395, mIoU: 0.3072\n",
      "Epoch [17/20], Step [25/328], Loss: 0.3341\n",
      "Epoch [17/20], Step [50/328], Loss: 0.3388\n",
      "Epoch [17/20], Step [75/328], Loss: 0.4258\n",
      "Epoch [17/20], Step [100/328], Loss: 0.3579\n",
      "Epoch [17/20], Step [125/328], Loss: 0.7270\n",
      "Epoch [17/20], Step [150/328], Loss: 0.9983\n",
      "Epoch [17/20], Step [175/328], Loss: 0.5175\n",
      "Epoch [17/20], Step [200/328], Loss: 0.3651\n",
      "Epoch [17/20], Step [225/328], Loss: 0.4472\n",
      "Epoch [17/20], Step [250/328], Loss: 0.2831\n",
      "Epoch [17/20], Step [275/328], Loss: 0.3847\n",
      "Epoch [17/20], Step [300/328], Loss: 0.5914\n",
      "Epoch [17/20], Step [325/328], Loss: 0.2792\n",
      "Start validation #17\n",
      "Validation #17  Average Loss: 0.4496, mIoU: 0.2980\n",
      "Epoch [18/20], Step [25/328], Loss: 0.2832\n",
      "Epoch [18/20], Step [50/328], Loss: 0.5285\n",
      "Epoch [18/20], Step [75/328], Loss: 0.7619\n",
      "Epoch [18/20], Step [100/328], Loss: 0.3001\n",
      "Epoch [18/20], Step [125/328], Loss: 0.3400\n",
      "Epoch [18/20], Step [150/328], Loss: 0.1688\n",
      "Epoch [18/20], Step [175/328], Loss: 0.2411\n",
      "Epoch [18/20], Step [200/328], Loss: 0.6160\n",
      "Epoch [18/20], Step [225/328], Loss: 0.4210\n",
      "Epoch [18/20], Step [250/328], Loss: 0.1708\n",
      "Epoch [18/20], Step [275/328], Loss: 0.3694\n",
      "Epoch [18/20], Step [300/328], Loss: 0.6982\n",
      "Epoch [18/20], Step [325/328], Loss: 0.2604\n",
      "Start validation #18\n",
      "Validation #18  Average Loss: 0.4788, mIoU: 0.2850\n",
      "Epoch [19/20], Step [25/328], Loss: 0.2288\n",
      "Epoch [19/20], Step [50/328], Loss: 0.1866\n",
      "Epoch [19/20], Step [75/328], Loss: 0.3315\n",
      "Epoch [19/20], Step [100/328], Loss: 0.4187\n",
      "Epoch [19/20], Step [125/328], Loss: 0.7028\n",
      "Epoch [19/20], Step [150/328], Loss: 0.2244\n",
      "Epoch [19/20], Step [175/328], Loss: 0.5070\n",
      "Epoch [19/20], Step [200/328], Loss: 0.2756\n",
      "Epoch [19/20], Step [225/328], Loss: 0.3699\n",
      "Epoch [19/20], Step [250/328], Loss: 0.4512\n",
      "Epoch [19/20], Step [275/328], Loss: 0.3699\n",
      "Epoch [19/20], Step [300/328], Loss: 0.7792\n",
      "Epoch [19/20], Step [325/328], Loss: 0.7179\n",
      "Start validation #19\n",
      "Validation #19  Average Loss: 0.4420, mIoU: 0.3007\n",
      "Epoch [20/20], Step [25/328], Loss: 0.2163\n",
      "Epoch [20/20], Step [50/328], Loss: 0.4528\n",
      "Epoch [20/20], Step [75/328], Loss: 0.4811\n",
      "Epoch [20/20], Step [100/328], Loss: 0.2615\n",
      "Epoch [20/20], Step [125/328], Loss: 0.3761\n",
      "Epoch [20/20], Step [150/328], Loss: 0.4132\n",
      "Epoch [20/20], Step [175/328], Loss: 0.4081\n",
      "Epoch [20/20], Step [200/328], Loss: 0.3477\n",
      "Epoch [20/20], Step [225/328], Loss: 0.3054\n",
      "Epoch [20/20], Step [250/328], Loss: 0.4130\n",
      "Epoch [20/20], Step [275/328], Loss: 0.5404\n",
      "Epoch [20/20], Step [300/328], Loss: 0.5293\n",
      "Epoch [20/20], Step [325/328], Loss: 0.2245\n",
      "Start validation #20\n",
      "Validation #20  Average Loss: 0.4278, mIoU: 0.3223\n",
      "Best performance at epoch: 20\n",
      "Save model in /opt/ml/code/saved\n",
      "end: 30일 21시 10분\n"
     ]
    }
   ],
   "source": [
    "# 학습시작 시간 출력\n",
    "s_dd, s_hh, s_mm = get_current_time()\n",
    "\n",
    "# 학습 시작\n",
    "train(num_epochs, model, train_loader, val_loader, criterion, optimizer, saved_dir, val_every, device)\n",
    "\n",
    "# 학습종료 시간 출력\n",
    "e_dd, e_hh, e_mm = get_current_time()\n",
    "print(f'start: {s_dd}일 {s_hh}시 {s_mm}분')\n",
    "print(f'end: {e_dd}일 {e_hh}시 {e_mm}분')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "138daf63-f111-497f-9bdd-3c670e8865fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 18695<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/opt/ml/code/notebook/wandb/run-20210430_104739-8tnlps8f/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/opt/ml/code/notebook/wandb/run-20210430_104739-8tnlps8f/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train_loss</td><td>0.22455</td></tr><tr><td>_runtime</td><td>4959</td></tr><tr><td>_timestamp</td><td>1619784618</td></tr><tr><td>_step</td><td>279</td></tr><tr><td>val_loss</td><td>0.42778</td></tr><tr><td>val_mIoU</td><td>0.32232</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train_loss</td><td>▄█▄▆▃▃▅▄▃▂▁▃█▃▂▃▆▃▁▃▂▃▂▃▄▂▃▂▄▁▃▄▂▄▆▂▁▃▂▁</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>val_loss</td><td>▇▆▇▅█▄▃▃▂▂▃▂▃▁▂▁▂▃▂▁</td></tr><tr><td>val_mIoU</td><td>▁▂▁▂▂▅▃▅▅▅▄▅▆▃▆▇▆▅▆█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">peach-night-15</strong>: <a href=\"https://wandb.ai/boostcamp-simple/p3-img-seg/runs/8tnlps8f\" target=\"_blank\">https://wandb.ai/boostcamp-simple/p3-img-seg/runs/8tnlps8f</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if use_wandb:\n",
    "    # wandb 종료\n",
    "    run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f420328-ed19-42b8-9d00-264fad8131eb",
   "metadata": {},
   "source": [
    "## 저장된 model 불러오기 (학습된 이후)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c50bb834-2f7d-4b2b-a28d-3fa607e6b8b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# best model 저장된 경로\n",
    "model_path = os.path.join(saved_dir, model_file_name)\n",
    "\n",
    "# best model 불러오기\n",
    "checkpoint = torch.load(model_path, map_location=device)\n",
    "model.load_state_dict(checkpoint)\n",
    "\n",
    "# 추론을 실행하기 전에는 반드시 설정 (batch normalization, dropout 를 평가 모드로 설정)\n",
    "# model.eval() # test 함수에서 model.eval() 실행\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37acda6-6f30-4154-b789-782c3552a07f",
   "metadata": {},
   "source": [
    "## submission을 위한 test 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba1912b7-1ddf-44b4-8456-1a4700beab35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, data_loader, device):\n",
    "    size = 256\n",
    "    transform = A.Compose([A.Resize(256, 256)])\n",
    "    print('Start prediction.')\n",
    "    model.eval()\n",
    "    \n",
    "    file_name_list = []\n",
    "    preds_array = np.empty((0, size*size), dtype=np.long)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for step, (imgs, image_infos) in enumerate(test_loader):\n",
    "\n",
    "            # inference (512 x 512)\n",
    "            outs = model(torch.stack(imgs).to(device))\n",
    "            oms = torch.argmax(outs.squeeze(), dim=1).detach().cpu().numpy()\n",
    "            \n",
    "            # resize (256 x 256)\n",
    "            temp_mask = []\n",
    "            for img, mask in zip(np.stack(imgs), oms):\n",
    "                transformed = transform(image=img, mask=mask)\n",
    "                mask = transformed['mask']\n",
    "                temp_mask.append(mask)\n",
    "\n",
    "            oms = np.array(temp_mask)\n",
    "            \n",
    "            oms = oms.reshape([oms.shape[0], size*size]).astype(int)\n",
    "            preds_array = np.vstack((preds_array, oms))\n",
    "            \n",
    "            file_name_list.append([i['file_name'] for i in image_infos])\n",
    "    print(\"End prediction.\")\n",
    "    file_names = [y for x in file_name_list for y in x]\n",
    "    \n",
    "    return file_names, preds_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7cbb38-3e70-455a-bf0b-ab20b3129158",
   "metadata": {},
   "source": [
    "## submission.csv 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce8ef792-06d6-4a7b-a527-40a76df45253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start prediction.\n",
      "End prediction.\n"
     ]
    }
   ],
   "source": [
    "# sample_submisson.csv 열기\n",
    "submission = pd.read_csv(os.path.join(submission_dir, 'sample_submission.csv'), index_col=None)\n",
    "\n",
    "# test set에 대한 prediction\n",
    "file_names, preds = test(model, test_loader, device)\n",
    "\n",
    "# PredictionString 대입\n",
    "for file_name, string in zip(file_names, preds):\n",
    "    submission = submission.append({\"image_id\" : file_name, \"PredictionString\" : ' '.join(str(e) for e in string.tolist())}, \n",
    "                                   ignore_index=True)\n",
    "\n",
    "# submission.csv로 저장\n",
    "submission.to_csv(os.path.join(submission_dir, submission_file_name), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1645ae5-a65b-4fd3-af7f-2f84c1727d43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
